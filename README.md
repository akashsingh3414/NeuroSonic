## Project Overview

This project involves building an **audio classification system** using **PyTorch**, designed to recognize different environmental sounds such as **dog barks** or **bird chirps**. It uses **Mel Spectrograms** to convert audio into visual representations, and a **Convolutional Neural Network (CNN)** based on **Residual Networks (ResNet)** to process and classify the audio data.

The model is deployed through a **web dashboard** built with **Next.js**, **React**, and **Tailwind CSS**, allowing users to upload audio files and view predictions along with visualizations of the modelâ€™s internal layers.

The project is beginner-friendly and uses only free, open-source tools. Future extensions will include **music classification**, enabling the system to identify genres, instruments, or moods from music tracks.
